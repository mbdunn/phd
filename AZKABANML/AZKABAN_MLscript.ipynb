{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40377a2",
   "metadata": {},
   "source": [
    "\n",
    "Originally created by Chelsey McGowan-Yallop, SAMS-UHI (sa06cm@sams.ac.uk)\n",
    "\n",
    "Modified by Muriel Dunn for fish mix analysis\n",
    "\n",
    "This script uses model-predicted TS(f) spectra to train a machine learning\n",
    "classifier, performs nested cross-validation, applies the classifier to\n",
    "measured TS(f) spectra and outputs results files.\n",
    "\n",
    "To use a different classifier, see the list of supported classifiers at:\n",
    "https://github.com/hyperopt/hyperopt-sklearn and set as clf.\n",
    "\n",
    "Sometimes the initial hyperparameter configuration selected by HyperOpt in each\n",
    "split in the outer loop will be unsuccessful and all trials will fail. The\n",
    "retry decorator forces it to try again until retry_limit is reached.\n",
    "\n",
    "OUTPUT FILES:\n",
    "    _NestedCV.pkl contains results of nested cross-validation procedure\n",
    "    _Predictions.pkl contains measured TS(f) spectra with predicted labels\n",
    "    _BestParams.pkl contains the optimal hyperparameters for the model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab9c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import hyperopt\n",
    "from hyperopt import tpe\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import timedelta\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "import sys, errno  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2319ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- USER-DETERMINED PARAMETERS -----------------------------------------------\n",
    "path = 'F:/Nya-AZKABAN/AZKABAN-fish2022/'\n",
    "# .CSV FILES FROM ECHOVIEW\n",
    "ts_SED_path = path+\"AtlanticCod_SED.csv\" # Path to Echoview TS(f) file\n",
    "ts_trackavg_path = path+\"AtlanticCod_SED.csv\" # Path to Echoview TS(f) file\n",
    "ts_trackavg_path = path+\"AtlanticCod_SED.csv\" # Path to Echoview TS(f) file\n",
    "min_range = 1.0 # Apply min range (m) to targets, else None\n",
    "max_range = 7.0 # Apply max range (m) to targets, else None\n",
    "\n",
    "# SCATTERING MODEL\n",
    "#model_path = path+\"AZKABAN_ZoopMix_data_newcopepod.feather\" # Path to model outputs\n",
    "#n_models_per_species = 1000 # No. of models per species\n",
    "\n",
    "# CLASSIFIER\n",
    "unique_id = '02-01-2023_kNN_AZKABAN' # Unique ID for output file paths\n",
    "clf = KNeighborsClassifier(unique_id)  # Classifier\n",
    "\n",
    "# NESTED CROSS-VALIDATION\n",
    "preprocessing = [] # List of sklearn pre-processing modules\n",
    "ex_preprocessing = [] # As above, see help(HyperoptEstimator) for info\n",
    "n_splits = 10 # Value of k for k-fold cross-validation in outer loop\n",
    "n_folds = 10 # Value of k for k-fold cross-validation in inner loop\n",
    "max_evals = 50 # No. of HyperOpt trials\n",
    "timeout = 300 # HyperOpt trial timeout (seconds)\n",
    "n_jobs = -1 # No. of jobs to run in parallel; -1 uses all processors\n",
    "retry_limit = 10 # No. of times to retry before failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386fc70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PUT THE FUN IN FUNCTIONS -------------------------------------------------\n",
    "\n",
    "def tsf_import(file_path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function imports wideband frequency response .csv files exported from\n",
    "    Echoview and performs some basic housekeeping.\n",
    "    \n",
    "    PARAMETERS:\n",
    "        file_path: Path to wideband frequency response .csv file from Echoview.\n",
    "        \n",
    "    RETURNS:\n",
    "        df: Pandas dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_datetime(df):\n",
    "        \"\"\"\n",
    "        Convert Echoview timestamps in imported .csv to datetime.\n",
    "        \"\"\"\n",
    "        df['Ping_microseconds'] = df.Ping_milliseconds * 1000\n",
    "        df['Ping_microseconds'] = [timedelta(microseconds = i) for i in df['Ping_microseconds']]\n",
    "        df['Datetime'] = df['Ping_date_Ping_time'] + df['Ping_microseconds']\n",
    "        df.drop(columns=['Ping_date_Ping_time',\n",
    "                         'Ping_milliseconds',\n",
    "                         'Ping_microseconds'],\n",
    "               inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    transposed_path = file_path[:-4] + '_transposed.csv'\n",
    "    if os.path.isfile(transposed_path) == True:\n",
    "        df = pd.read_csv(transposed_path,\n",
    "                         index_col='Target_index',\n",
    "                         skiprows=1,\n",
    "                         skipfooter=2,\n",
    "                         engine='python',\n",
    "                         parse_dates=[['Ping_date', 'Ping_time']])\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, low_memory=False).T\n",
    "        file_path = transposed_path\n",
    "        df.to_csv(path_or_buf=file_path)\n",
    "        print('A transposed TS(f) file was created at: \\n' + str(file_path))    \n",
    "        df = pd.read_csv(file_path,\n",
    "                         index_col='Target_index',\n",
    "                         skiprows=1,\n",
    "                         skipfooter=2,\n",
    "                         engine='python',\n",
    "                         parse_dates=[['Ping_date', 'Ping_time']])\n",
    "    \n",
    "    df = get_datetime(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e54ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(retry_limit))\n",
    "def nested_cv(X, y, model, n_splits, n_folds, unique_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function performs nested cross-validation with Bayesian hyperparameter\n",
    "    optimisation. It uses stratified k-fold cross-validation in both the inner\n",
    "    and outer loops. After each outer loop, it outputs the results to a .pkl\n",
    "    file. As there is an element of randomness to the optimisation procedure,\n",
    "    sometimes all trials will fail. If you re-run the script, it will import\n",
    "    the incomplete .pkl file and try again.\n",
    "    \n",
    "    Note that this is a modified version that uses F1 score as the evaluation\n",
    "    metric. It also calculates class-specific F1 scores and confusion matrices,\n",
    "    which are added to the output dataframe.\n",
    "    \n",
    "    PARAMETERS:\n",
    "        X: data minus labels\n",
    "        y: labels\n",
    "        model: HyperoptEstimator object\n",
    "        n_splits: # of splits to use in outer K-fold cross-validation\n",
    "        n_folds: # of folds to use in inner K-fold cross-validation\n",
    "        unique_id: Unique name string for file output path\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_splits,\n",
    "                         shuffle=True,\n",
    "                         random_state=42) # Outer CV\n",
    "    \n",
    "    i_start = 0\n",
    "    i_list = []\n",
    "    results_df = None\n",
    "    cv_path = unique_id + '_NestedCV.pkl'\n",
    "        \n",
    "    if os.path.isfile(cv_path) == True: # If CV is incomplete, resume\n",
    "        results_df = pd.read_pickle(cv_path)\n",
    "        i_start = results_df.Outer_fold.max() + 1\n",
    "        print('Resuming cross-validation from fold ' + str(i_start + 1))\n",
    "        \n",
    "    # Generate indices to split data by StratifiedKFold\n",
    "    # Append indices for each fold to list    \n",
    "    for tr_i, te_i in cv.split(X,y):\n",
    "        i_list.append([tr_i, te_i])\n",
    "    \n",
    "    # For each fold...\n",
    "    for i in range(i_start, len(i_list)):\n",
    "        results_list = []\n",
    "        print('Beginning fold ' + str(i+1) + ' of ' + str(len(i_list)))\n",
    "        \n",
    "        # Split data into training and test tests\n",
    "        X_train = X.loc[X.index.intersection(i_list[i][0])]\n",
    "        y_train = y.loc[y.index.intersection(i_list[i][0])]\n",
    "        X_test = X.loc[X.index.intersection(i_list[i][1])]\n",
    "        y_test = y.loc[y.index.intersection(i_list[i][1])]\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        # Fit the HyperoptEstimator to training data (optimise model)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  n_folds=n_folds, # Inner stratified k-fold CV\n",
    "                  cv_shuffle=True)\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "\n",
    "        # Use optimised model to predict labels for test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred, average='weighted') # Evaluate\n",
    "        \n",
    "        # Everything below: formats and/or calculates results for output file\n",
    "        sorted_labels = np.sort(y_test.unique())\n",
    "        unweighted_score = f1_score(y_test, y_pred,\n",
    "                                    average=None,\n",
    "                                    labels=sorted_labels)\n",
    "        c_matrix = confusion_matrix(y_test, y_pred,\n",
    "                                    labels=sorted_labels)\n",
    "\n",
    "        for trial in range(len(model.trials.trials)):\n",
    "                if model.trials.trials[trial].get('result').get('status') == 'ok':\n",
    "                    trial_loss = model.trials.trials[trial].get('result').get('loss')\n",
    "                    trial_duration = model.trials.trials[trial].get('result').get('duration')\n",
    "                else:\n",
    "                    trial_loss = np.nan\n",
    "                    trial_duration = np.nan\n",
    "            \n",
    "                results_list.append([i,\n",
    "                                     score,\n",
    "                                     unweighted_score,\n",
    "                                     le.inverse_transform(sorted_labels),\n",
    "                                     c_matrix,\n",
    "                                     duration,\n",
    "                                     trial,\n",
    "                                     trial_loss,\n",
    "                                     trial_duration])\n",
    "        \n",
    "        append_df = pd.DataFrame(results_list,\n",
    "                                 columns=['Outer_fold',\n",
    "                                          'Outer_score',\n",
    "                                          'Outer_unweighted_scores',\n",
    "                                          'Outer_unweighted_score_labels',\n",
    "                                          'Outer_confusion_matrix',\n",
    "                                          'Outer_training_duration',\n",
    "                                          'Trial',\n",
    "                                          'Trial_loss',\n",
    "                                          'Trial_duration'])\n",
    "        if i == i_start:\n",
    "            if results_df is not None:\n",
    "                final_df = pd.concat([results_df,\n",
    "                                      append_df],\n",
    "                                      ignore_index=True)\n",
    "            else:\n",
    "                final_df = append_df\n",
    "            final_df.to_pickle(cv_path)\n",
    "        \n",
    "        else:\n",
    "            results_df = pd.read_pickle(cv_path)\n",
    "            final_df = pd.concat([results_df,\n",
    "                                  append_df],\n",
    "                                  ignore_index=True)\n",
    "            final_df.to_pickle(cv_path)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cfb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function for HyperOpt.\n",
    "    Uses F1 score instead of accuracy score, as the latter is inappropriate\n",
    "    for multi-class classification.\n",
    "    \"\"\"\n",
    "    return 1.0 - f1_score(y_true, y_pred, average='weighted')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b050fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():    \n",
    "    # -- IMPORT FILES ---------------------------------------------------------\n",
    "     \n",
    "    measured_df = tsf_import(tsf_path) # Measured TS(f)\n",
    "    model_df = pd.read_feather(model_path) # Modelled TS(f)\n",
    "\n",
    "    # -- RESTRUCTURE MODEL DATA -----------------------------------------------\n",
    "\n",
    "    measured_frequency = [float(i) for i in measured_df.columns.values[3:-1]]\n",
    "    n_model_f_bins = len(model_df.freq.unique()) # No. freq bins in model data\n",
    "    n_species = len(model_df.spec.unique()) # No. species in model data\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    start_lim = 0\n",
    "    stop_lim = n_model_f_bins\n",
    "\n",
    "    for i in range(n_species * n_models_per_species):\n",
    "        TS_array = model_df.TS[start_lim:stop_lim].values\n",
    "        species_label = model_df.spec[start_lim:stop_lim].values[0]\n",
    "\n",
    "        X_list.append(TS_array)\n",
    "        y_list.append(species_label)\n",
    "\n",
    "        start_lim += n_model_f_bins\n",
    "        stop_lim += n_model_f_bins\n",
    "\n",
    "    model_df = pd.DataFrame(X_list, columns=measured_frequency)\n",
    "    model_df['Species'] = y_list\n",
    "\n",
    "    # -- WRANGLE DATA ---------------------------------------------------------\n",
    "\n",
    "    le = LabelEncoder() # Maps labels -> int (e.g. Copepods -> 0, Krill -> 1)\n",
    "    model_df['Species'] = le.fit_transform(model_df.Species)\n",
    "    X = model_df.iloc[:, :-1] # Features, TS(f) only\n",
    "    y = model_df.Species # Labels\n",
    "\n",
    "    if min_range != None:\n",
    "        measured_df = measured_df[measured_df.Range > min_range]\n",
    "\n",
    "    if max_range != None:\n",
    "        measured_df = measured_df[measured_df.Range < max_range]\n",
    "\n",
    "    measured_X = measured_df.iloc[:, 3:-1] # Features, TS(f) only\n",
    "\n",
    "    # -- NESTED CROSS-VALIDATION ----------------------------------------------\n",
    "\n",
    "    model = HyperoptEstimator(classifier = clf,\n",
    "                              preprocessing = preprocessing,\n",
    "                              ex_preprocs = ex_preprocessing,\n",
    "                              algo = tpe.suggest,\n",
    "                              trial_timeout = timeout,\n",
    "                              loss_fn = f1_loss,\n",
    "                              max_evals = max_evals)#,\n",
    "                              #n_jobs = n_jobs)\n",
    "\n",
    "    nested_cv(X, y, model, n_splits, n_folds, unique_id)\n",
    "\n",
    "    # -- RETRAIN MODEL --------------------------------------------------------\n",
    "\n",
    "    print('Retraining model on full dataset')\n",
    "\n",
    "    model = HyperoptEstimator(classifier = clf,\n",
    "                              preprocessing = preprocessing,\n",
    "                              ex_preprocs = ex_preprocessing,\n",
    "                              algo = tpe.suggest,\n",
    "                              trial_timeout = timeout,\n",
    "                              loss_fn = f1_loss,\n",
    "                              max_evals = max_evals)#,\n",
    "                              #n_jobs = n_jobs)\n",
    "\n",
    "    model.fit(X, y, n_folds=n_folds, cv_shuffle=True)\n",
    "\n",
    "    # -- PREDICT CLASSES FOR NEW DATA -----------------------------------------\n",
    "\n",
    "    print('Classifying new data')\n",
    "\n",
    "    y_pred = model.predict(measured_X) # Predict classes for measured TS(f)\n",
    "    y_pred = le.inverse_transform(y_pred) # Transform labels back to species\n",
    "\n",
    "    # -- OUTPUT RESULTS -------------------------------------------------------\n",
    "\n",
    "    measured_df['Prediction'] = y_pred\n",
    "    measured_df.to_pickle(unique_id + '_Predictions.pkl')\n",
    "\n",
    "    with open(unique_id + '_BestParams.pkl', 'wb') as handle:\n",
    "        pickle.dump(model.best_model(), handle)\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "824770b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A transposed TS(f) file was created at: \n",
      "F:/Nya-AZKABAN/AZKABAN-fish2022/AtlanticCod_SED_transposed.csv\n"
     ]
    }
   ],
   "source": [
    "measured_df = tsf_import(tsf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83a12e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ping_index</th>\n",
       "      <th>Range</th>\n",
       "      <th>Depth</th>\n",
       "      <th>90.000</th>\n",
       "      <th>90.500</th>\n",
       "      <th>91.000</th>\n",
       "      <th>91.500</th>\n",
       "      <th>92.000</th>\n",
       "      <th>92.500</th>\n",
       "      <th>93.000</th>\n",
       "      <th>...</th>\n",
       "      <th>166.000</th>\n",
       "      <th>166.500</th>\n",
       "      <th>167.000</th>\n",
       "      <th>167.500</th>\n",
       "      <th>168.000</th>\n",
       "      <th>168.500</th>\n",
       "      <th>169.000</th>\n",
       "      <th>169.500</th>\n",
       "      <th>170.000</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.628848</td>\n",
       "      <td>5.617238</td>\n",
       "      <td>-31.915427</td>\n",
       "      <td>-32.438779</td>\n",
       "      <td>-32.639425</td>\n",
       "      <td>-32.373674</td>\n",
       "      <td>-32.181812</td>\n",
       "      <td>-32.299312</td>\n",
       "      <td>-32.761376</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.172522</td>\n",
       "      <td>-46.564779</td>\n",
       "      <td>-47.031860</td>\n",
       "      <td>-47.691934</td>\n",
       "      <td>-48.610345</td>\n",
       "      <td>-49.751749</td>\n",
       "      <td>-50.981897</td>\n",
       "      <td>-51.929721</td>\n",
       "      <td>-52.222216</td>\n",
       "      <td>2022-01-13 10:30:20.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.591144</td>\n",
       "      <td>6.571238</td>\n",
       "      <td>-36.114666</td>\n",
       "      <td>-32.214917</td>\n",
       "      <td>-30.416021</td>\n",
       "      <td>-29.992647</td>\n",
       "      <td>-31.018295</td>\n",
       "      <td>-33.340891</td>\n",
       "      <td>-35.952621</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.671039</td>\n",
       "      <td>-56.296144</td>\n",
       "      <td>-67.409275</td>\n",
       "      <td>-63.254305</td>\n",
       "      <td>-61.576541</td>\n",
       "      <td>-63.948518</td>\n",
       "      <td>-64.609738</td>\n",
       "      <td>-65.216180</td>\n",
       "      <td>-69.957655</td>\n",
       "      <td>2022-01-13 10:30:20.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.623051</td>\n",
       "      <td>5.610025</td>\n",
       "      <td>-38.280398</td>\n",
       "      <td>-36.966869</td>\n",
       "      <td>-36.781604</td>\n",
       "      <td>-37.251602</td>\n",
       "      <td>-38.400912</td>\n",
       "      <td>-39.620860</td>\n",
       "      <td>-39.941762</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.052424</td>\n",
       "      <td>-64.412874</td>\n",
       "      <td>-66.698775</td>\n",
       "      <td>-64.882859</td>\n",
       "      <td>-60.389657</td>\n",
       "      <td>-56.257941</td>\n",
       "      <td>-53.426689</td>\n",
       "      <td>-51.985144</td>\n",
       "      <td>-51.928260</td>\n",
       "      <td>2022-01-13 10:30:20.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5.640442</td>\n",
       "      <td>5.626242</td>\n",
       "      <td>-36.151157</td>\n",
       "      <td>-36.138085</td>\n",
       "      <td>-36.823339</td>\n",
       "      <td>-37.760591</td>\n",
       "      <td>-38.726831</td>\n",
       "      <td>-39.061169</td>\n",
       "      <td>-38.784957</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.422621</td>\n",
       "      <td>-64.317494</td>\n",
       "      <td>-60.951879</td>\n",
       "      <td>-58.635508</td>\n",
       "      <td>-57.245403</td>\n",
       "      <td>-54.419167</td>\n",
       "      <td>-51.911909</td>\n",
       "      <td>-51.049755</td>\n",
       "      <td>-51.767891</td>\n",
       "      <td>2022-01-13 10:30:20.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6.614331</td>\n",
       "      <td>6.592303</td>\n",
       "      <td>-30.269844</td>\n",
       "      <td>-31.348255</td>\n",
       "      <td>-33.214381</td>\n",
       "      <td>-34.694713</td>\n",
       "      <td>-34.609010</td>\n",
       "      <td>-33.484105</td>\n",
       "      <td>-32.724687</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.959937</td>\n",
       "      <td>-40.213835</td>\n",
       "      <td>-41.258542</td>\n",
       "      <td>-43.248557</td>\n",
       "      <td>-45.707007</td>\n",
       "      <td>-46.949574</td>\n",
       "      <td>-46.916999</td>\n",
       "      <td>-47.852483</td>\n",
       "      <td>-51.539544</td>\n",
       "      <td>2022-01-13 10:30:20.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79385</th>\n",
       "      <td>35617</td>\n",
       "      <td>5.796960</td>\n",
       "      <td>5.795151</td>\n",
       "      <td>-39.339739</td>\n",
       "      <td>-38.727011</td>\n",
       "      <td>-38.249553</td>\n",
       "      <td>-37.873847</td>\n",
       "      <td>-37.692556</td>\n",
       "      <td>-37.701828</td>\n",
       "      <td>-37.709297</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.981680</td>\n",
       "      <td>-38.673042</td>\n",
       "      <td>-39.446617</td>\n",
       "      <td>-40.191212</td>\n",
       "      <td>-40.784936</td>\n",
       "      <td>-41.194848</td>\n",
       "      <td>-41.526568</td>\n",
       "      <td>-41.963395</td>\n",
       "      <td>-42.648993</td>\n",
       "      <td>2022-01-13 14:44:58.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79386</th>\n",
       "      <td>35618</td>\n",
       "      <td>4.162217</td>\n",
       "      <td>4.161632</td>\n",
       "      <td>-30.626774</td>\n",
       "      <td>-30.016487</td>\n",
       "      <td>-29.644226</td>\n",
       "      <td>-29.524220</td>\n",
       "      <td>-29.748905</td>\n",
       "      <td>-30.245836</td>\n",
       "      <td>-30.668648</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.283316</td>\n",
       "      <td>-37.020772</td>\n",
       "      <td>-37.024834</td>\n",
       "      <td>-37.488932</td>\n",
       "      <td>-38.492096</td>\n",
       "      <td>-39.900057</td>\n",
       "      <td>-41.069759</td>\n",
       "      <td>-41.073801</td>\n",
       "      <td>-40.170357</td>\n",
       "      <td>2022-01-13 14:44:59.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79387</th>\n",
       "      <td>35618</td>\n",
       "      <td>4.394096</td>\n",
       "      <td>4.391965</td>\n",
       "      <td>-25.452183</td>\n",
       "      <td>-27.662271</td>\n",
       "      <td>-29.283096</td>\n",
       "      <td>-29.702831</td>\n",
       "      <td>-28.553149</td>\n",
       "      <td>-27.898429</td>\n",
       "      <td>-29.118468</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.351394</td>\n",
       "      <td>-36.695058</td>\n",
       "      <td>-40.896311</td>\n",
       "      <td>-51.335559</td>\n",
       "      <td>-43.740377</td>\n",
       "      <td>-38.536115</td>\n",
       "      <td>-36.204435</td>\n",
       "      <td>-35.100141</td>\n",
       "      <td>-34.984296</td>\n",
       "      <td>2022-01-13 14:44:59.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79388</th>\n",
       "      <td>35618</td>\n",
       "      <td>4.649162</td>\n",
       "      <td>4.633902</td>\n",
       "      <td>-30.557550</td>\n",
       "      <td>-31.678673</td>\n",
       "      <td>-33.865435</td>\n",
       "      <td>-38.026749</td>\n",
       "      <td>-37.591305</td>\n",
       "      <td>-34.789576</td>\n",
       "      <td>-34.422944</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.283642</td>\n",
       "      <td>-31.704230</td>\n",
       "      <td>-30.846795</td>\n",
       "      <td>-30.562482</td>\n",
       "      <td>-30.051977</td>\n",
       "      <td>-29.038058</td>\n",
       "      <td>-28.314656</td>\n",
       "      <td>-28.159899</td>\n",
       "      <td>-27.703099</td>\n",
       "      <td>2022-01-13 14:44:59.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79389</th>\n",
       "      <td>35618</td>\n",
       "      <td>5.796960</td>\n",
       "      <td>5.794997</td>\n",
       "      <td>-37.899095</td>\n",
       "      <td>-37.416057</td>\n",
       "      <td>-36.962514</td>\n",
       "      <td>-36.543016</td>\n",
       "      <td>-36.310331</td>\n",
       "      <td>-36.309520</td>\n",
       "      <td>-36.360645</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.567483</td>\n",
       "      <td>-37.099950</td>\n",
       "      <td>-37.670744</td>\n",
       "      <td>-38.220103</td>\n",
       "      <td>-38.705320</td>\n",
       "      <td>-39.141465</td>\n",
       "      <td>-39.603321</td>\n",
       "      <td>-40.183583</td>\n",
       "      <td>-40.927181</td>\n",
       "      <td>2022-01-13 14:44:59.255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79390 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ping_index     Range     Depth     90.000     90.500     91.000  \\\n",
       "Target_index                                                                    \n",
       "0                      0  5.628848  5.617238 -31.915427 -32.438779 -32.639425   \n",
       "1                      0  6.591144  6.571238 -36.114666 -32.214917 -30.416021   \n",
       "2                      1  5.623051  5.610025 -38.280398 -36.966869 -36.781604   \n",
       "3                      1  5.640442  5.626242 -36.151157 -36.138085 -36.823339   \n",
       "4                      1  6.614331  6.592303 -30.269844 -31.348255 -33.214381   \n",
       "...                  ...       ...       ...        ...        ...        ...   \n",
       "79385              35617  5.796960  5.795151 -39.339739 -38.727011 -38.249553   \n",
       "79386              35618  4.162217  4.161632 -30.626774 -30.016487 -29.644226   \n",
       "79387              35618  4.394096  4.391965 -25.452183 -27.662271 -29.283096   \n",
       "79388              35618  4.649162  4.633902 -30.557550 -31.678673 -33.865435   \n",
       "79389              35618  5.796960  5.794997 -37.899095 -37.416057 -36.962514   \n",
       "\n",
       "                 91.500     92.000     92.500     93.000  ...    166.000  \\\n",
       "Target_index                                              ...              \n",
       "0            -32.373674 -32.181812 -32.299312 -32.761376  ... -46.172522   \n",
       "1            -29.992647 -31.018295 -33.340891 -35.952621  ... -50.671039   \n",
       "2            -37.251602 -38.400912 -39.620860 -39.941762  ... -61.052424   \n",
       "3            -37.760591 -38.726831 -39.061169 -38.784957  ... -60.422621   \n",
       "4            -34.694713 -34.609010 -33.484105 -32.724687  ... -39.959937   \n",
       "...                 ...        ...        ...        ...  ...        ...   \n",
       "79385        -37.873847 -37.692556 -37.701828 -37.709297  ... -37.981680   \n",
       "79386        -29.524220 -29.748905 -30.245836 -30.668648  ... -37.283316   \n",
       "79387        -29.702831 -28.553149 -27.898429 -29.118468  ... -35.351394   \n",
       "79388        -38.026749 -37.591305 -34.789576 -34.422944  ... -33.283642   \n",
       "79389        -36.543016 -36.310331 -36.309520 -36.360645  ... -36.567483   \n",
       "\n",
       "                166.500    167.000    167.500    168.000    168.500  \\\n",
       "Target_index                                                          \n",
       "0            -46.564779 -47.031860 -47.691934 -48.610345 -49.751749   \n",
       "1            -56.296144 -67.409275 -63.254305 -61.576541 -63.948518   \n",
       "2            -64.412874 -66.698775 -64.882859 -60.389657 -56.257941   \n",
       "3            -64.317494 -60.951879 -58.635508 -57.245403 -54.419167   \n",
       "4            -40.213835 -41.258542 -43.248557 -45.707007 -46.949574   \n",
       "...                 ...        ...        ...        ...        ...   \n",
       "79385        -38.673042 -39.446617 -40.191212 -40.784936 -41.194848   \n",
       "79386        -37.020772 -37.024834 -37.488932 -38.492096 -39.900057   \n",
       "79387        -36.695058 -40.896311 -51.335559 -43.740377 -38.536115   \n",
       "79388        -31.704230 -30.846795 -30.562482 -30.051977 -29.038058   \n",
       "79389        -37.099950 -37.670744 -38.220103 -38.705320 -39.141465   \n",
       "\n",
       "                169.000    169.500    170.000                Datetime  \n",
       "Target_index                                                           \n",
       "0            -50.981897 -51.929721 -52.222216 2022-01-13 10:30:20.119  \n",
       "1            -64.609738 -65.216180 -69.957655 2022-01-13 10:30:20.119  \n",
       "2            -53.426689 -51.985144 -51.928260 2022-01-13 10:30:20.674  \n",
       "3            -51.911909 -51.049755 -51.767891 2022-01-13 10:30:20.674  \n",
       "4            -46.916999 -47.852483 -51.539544 2022-01-13 10:30:20.674  \n",
       "...                 ...        ...        ...                     ...  \n",
       "79385        -41.526568 -41.963395 -42.648993 2022-01-13 14:44:58.812  \n",
       "79386        -41.069759 -41.073801 -40.170357 2022-01-13 14:44:59.255  \n",
       "79387        -36.204435 -35.100141 -34.984296 2022-01-13 14:44:59.255  \n",
       "79388        -28.314656 -28.159899 -27.703099 2022-01-13 14:44:59.255  \n",
       "79389        -39.603321 -40.183583 -40.927181 2022-01-13 14:44:59.255  \n",
       "\n",
       "[79390 rows x 165 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a649e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
