{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40377a2",
   "metadata": {},
   "source": [
    "\n",
    "Originally created by Chelsey McGowan-Yallop, SAMS-UHI (sa06cm@sams.ac.uk)\n",
    "\n",
    "Modified by Muriel Dunn for fish mix analysis\n",
    "\n",
    "This script uses model-predicted TS(f) spectra to train a machine learning\n",
    "classifier, performs nested cross-validation, applies the classifier to\n",
    "measured TS(f) spectra and outputs results files.\n",
    "\n",
    "To use a different classifier, see the list of supported classifiers at:\n",
    "https://github.com/hyperopt/hyperopt-sklearn and set as clf.\n",
    "\n",
    "Sometimes the initial hyperparameter configuration selected by HyperOpt in each\n",
    "split in the outer loop will be unsuccessful and all trials will fail. The\n",
    "retry decorator forces it to try again until retry_limit is reached.\n",
    "\n",
    "OUTPUT FILES:\n",
    "    _NestedCV.pkl contains results of nested cross-validation procedure\n",
    "    _Predictions.pkl contains measured TS(f) spectra with predicted labels\n",
    "    _BestParams.pkl contains the optimal hyperparameters for the model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab9c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import hyperopt\n",
    "from hyperopt import tpe\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import timedelta\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "import sys, errno  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2319ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- USER-DETERMINED PARAMETERS -----------------------------------------------\n",
    "path = 'C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/AZKABAN-light/ZoopMix_paper/'\n",
    "# .CSV FILES FROM ECHOVIEW\n",
    "ts_SED_path = path+\"SED_ZoopMix_FTwindow33pl.csv\" # Path to Echoview TS(f) file\n",
    "ts_trackavg_path = path+\"SED_ZoopMix_FTwindow33pl_tracks.csv\" # Path to Echoview TS(f) file\n",
    "ts_trackavg_path = path+\"SED_ZoopMix_FTwindow33pl_tracks-averaged.csv\" # Path to Echoview TS(f) file\n",
    "\n",
    "\n",
    "# SCATTERING MODEL\n",
    "#model_path = path+\"AZKABAN_ZoopMix_data_newcopepod.feather\" # Path to model outputs\n",
    "#n_models_per_species = 1000 # No. of models per species\n",
    "\n",
    "# CLASSIFIER\n",
    "unique_id = '02-01-2023_kNN_AZKABAN' # Unique ID for output file paths\n",
    "clf = KNeighborsClassifier(unique_id)  # Classifier\n",
    "\n",
    "# NESTED CROSS-VALIDATION\n",
    "preprocessing = [] # List of sklearn pre-processing modules\n",
    "ex_preprocessing = [] # As above, see help(HyperoptEstimator) for info\n",
    "n_splits = 10 # Value of k for k-fold cross-validation in outer loop\n",
    "n_folds = 10 # Value of k for k-fold cross-validation in inner loop\n",
    "max_evals = 50 # No. of HyperOpt trials\n",
    "timeout = 300 # HyperOpt trial timeout (seconds)\n",
    "n_jobs = -1 # No. of jobs to run in parallel; -1 uses all processors\n",
    "retry_limit = 10 # No. of times to retry before failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386fc70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- PUT THE FUN IN FUNCTIONS -------------------------------------------------\n",
    "\n",
    "def tsf_import(file_path):\n",
    "\n",
    "    \"\"\"\n",
    "    This function imports wideband frequency response .csv files exported from\n",
    "    Echoview and performs some basic housekeeping.\n",
    "    \n",
    "    PARAMETERS:\n",
    "        file_path: Path to wideband frequency response .csv file from Echoview.\n",
    "        \n",
    "    RETURNS:\n",
    "        df: Pandas dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_datetime(df):\n",
    "        \"\"\"\n",
    "        Convert Echoview timestamps in imported .csv to datetime.\n",
    "        \"\"\"\n",
    "        df['Ping_microseconds'] = df.Ping_milliseconds * 1000\n",
    "        df['Ping_microseconds'] = [timedelta(microseconds = i) for i in df['Ping_microseconds']]\n",
    "        df['Datetime'] = df['Ping_date_Ping_time'] + df['Ping_microseconds']\n",
    "        df.drop(columns=['Ping_date_Ping_time',\n",
    "                         'Ping_milliseconds',\n",
    "                         'Ping_microseconds'],\n",
    "               inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    transposed_path = file_path[:-4] + '_transposed.csv'\n",
    "    if os.path.isfile(transposed_path) == True:\n",
    "        df = pd.read_csv(transposed_path,\n",
    "                         index_col='Target_index',\n",
    "                         skiprows=1,\n",
    "                         skipfooter=2,\n",
    "                         engine='python',\n",
    "                         parse_dates=[['Ping_date', 'Ping_time']])\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, low_memory=False).T\n",
    "        file_path = transposed_path\n",
    "        df.to_csv(path_or_buf=file_path)\n",
    "        print('A transposed TS(f) file was created at: \\n' + str(file_path))    \n",
    "        df = pd.read_csv(file_path,\n",
    "                         index_col='Target_index',\n",
    "                         skiprows=1,\n",
    "                         skipfooter=2,\n",
    "                         engine='python',\n",
    "                         parse_dates=[['Ping_date', 'Ping_time']])\n",
    "    \n",
    "    df = get_datetime(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e54ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(retry_limit))\n",
    "def nested_cv(X, y, model, n_splits, n_folds, unique_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function performs nested cross-validation with Bayesian hyperparameter\n",
    "    optimisation. It uses stratified k-fold cross-validation in both the inner\n",
    "    and outer loops. After each outer loop, it outputs the results to a .pkl\n",
    "    file. As there is an element of randomness to the optimisation procedure,\n",
    "    sometimes all trials will fail. If you re-run the script, it will import\n",
    "    the incomplete .pkl file and try again.\n",
    "    \n",
    "    Note that this is a modified version that uses F1 score as the evaluation\n",
    "    metric. It also calculates class-specific F1 scores and confusion matrices,\n",
    "    which are added to the output dataframe.\n",
    "    \n",
    "    PARAMETERS:\n",
    "        X: data minus labels\n",
    "        y: labels\n",
    "        model: HyperoptEstimator object\n",
    "        n_splits: # of splits to use in outer K-fold cross-validation\n",
    "        n_folds: # of folds to use in inner K-fold cross-validation\n",
    "        unique_id: Unique name string for file output path\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_splits,\n",
    "                         shuffle=True,\n",
    "                         random_state=42) # Outer CV\n",
    "    \n",
    "    i_start = 0\n",
    "    i_list = []\n",
    "    results_df = None\n",
    "    cv_path = unique_id + '_NestedCV.pkl'\n",
    "        \n",
    "    if os.path.isfile(cv_path) == True: # If CV is incomplete, resume\n",
    "        results_df = pd.read_pickle(cv_path)\n",
    "        i_start = results_df.Outer_fold.max() + 1\n",
    "        print('Resuming cross-validation from fold ' + str(i_start + 1))\n",
    "        \n",
    "    # Generate indices to split data by StratifiedKFold\n",
    "    # Append indices for each fold to list    \n",
    "    for tr_i, te_i in cv.split(X,y):\n",
    "        i_list.append([tr_i, te_i])\n",
    "    \n",
    "    # For each fold...\n",
    "    for i in range(i_start, len(i_list)):\n",
    "        results_list = []\n",
    "        print('Beginning fold ' + str(i+1) + ' of ' + str(len(i_list)))\n",
    "        \n",
    "        # Split data into training and test tests\n",
    "        X_train = X.loc[X.index.intersection(i_list[i][0])]\n",
    "        y_train = y.loc[y.index.intersection(i_list[i][0])]\n",
    "        X_test = X.loc[X.index.intersection(i_list[i][1])]\n",
    "        y_test = y.loc[y.index.intersection(i_list[i][1])]\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        # Fit the HyperoptEstimator to training data (optimise model)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  n_folds=n_folds, # Inner stratified k-fold CV\n",
    "                  cv_shuffle=True)\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "\n",
    "        # Use optimised model to predict labels for test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred, average='weighted') # Evaluate\n",
    "        \n",
    "        # Everything below: formats and/or calculates results for output file\n",
    "        sorted_labels = np.sort(y_test.unique())\n",
    "        unweighted_score = f1_score(y_test, y_pred,\n",
    "                                    average=None,\n",
    "                                    labels=sorted_labels)\n",
    "        c_matrix = confusion_matrix(y_test, y_pred,\n",
    "                                    labels=sorted_labels)\n",
    "\n",
    "        for trial in range(len(model.trials.trials)):\n",
    "                if model.trials.trials[trial].get('result').get('status') == 'ok':\n",
    "                    trial_loss = model.trials.trials[trial].get('result').get('loss')\n",
    "                    trial_duration = model.trials.trials[trial].get('result').get('duration')\n",
    "                else:\n",
    "                    trial_loss = np.nan\n",
    "                    trial_duration = np.nan\n",
    "            \n",
    "                results_list.append([i,\n",
    "                                     score,\n",
    "                                     unweighted_score,\n",
    "                                     le.inverse_transform(sorted_labels),\n",
    "                                     c_matrix,\n",
    "                                     duration,\n",
    "                                     trial,\n",
    "                                     trial_loss,\n",
    "                                     trial_duration])\n",
    "        \n",
    "        append_df = pd.DataFrame(results_list,\n",
    "                                 columns=['Outer_fold',\n",
    "                                          'Outer_score',\n",
    "                                          'Outer_unweighted_scores',\n",
    "                                          'Outer_unweighted_score_labels',\n",
    "                                          'Outer_confusion_matrix',\n",
    "                                          'Outer_training_duration',\n",
    "                                          'Trial',\n",
    "                                          'Trial_loss',\n",
    "                                          'Trial_duration'])\n",
    "        if i == i_start:\n",
    "            if results_df is not None:\n",
    "                final_df = pd.concat([results_df,\n",
    "                                      append_df],\n",
    "                                      ignore_index=True)\n",
    "            else:\n",
    "                final_df = append_df\n",
    "            final_df.to_pickle(cv_path)\n",
    "        \n",
    "        else:\n",
    "            results_df = pd.read_pickle(cv_path)\n",
    "            final_df = pd.concat([results_df,\n",
    "                                  append_df],\n",
    "                                  ignore_index=True)\n",
    "            final_df.to_pickle(cv_path)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cfb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function for HyperOpt.\n",
    "    Uses F1 score instead of accuracy score, as the latter is inappropriate\n",
    "    for multi-class classification.\n",
    "    \"\"\"\n",
    "    return 1.0 - f1_score(y_true, y_pred, average='weighted')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b050fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():    \n",
    "    # -- IMPORT FILES ---------------------------------------------------------\n",
    "     \n",
    "    measured_df = tsf_import(tsf_path) # Measured TS(f)\n",
    "    model_df = pd.read_feather(model_path) # Modelled TS(f)\n",
    "\n",
    "    # -- RESTRUCTURE MODEL DATA -----------------------------------------------\n",
    "\n",
    "    measured_frequency = [float(i) for i in measured_df.columns.values[3:-1]]\n",
    "    n_model_f_bins = len(model_df.freq.unique()) # No. freq bins in model data\n",
    "    n_species = len(model_df.spec.unique()) # No. species in model data\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    start_lim = 0\n",
    "    stop_lim = n_model_f_bins\n",
    "\n",
    "    for i in range(n_species * n_models_per_species):\n",
    "        TS_array = model_df.TS[start_lim:stop_lim].values\n",
    "        species_label = model_df.spec[start_lim:stop_lim].values[0]\n",
    "\n",
    "        X_list.append(TS_array)\n",
    "        y_list.append(species_label)\n",
    "\n",
    "        start_lim += n_model_f_bins\n",
    "        stop_lim += n_model_f_bins\n",
    "\n",
    "    model_df = pd.DataFrame(X_list, columns=measured_frequency)\n",
    "    model_df['Species'] = y_list\n",
    "\n",
    "    # -- WRANGLE DATA ---------------------------------------------------------\n",
    "\n",
    "    le = LabelEncoder() # Maps labels -> int (e.g. Copepods -> 0, Krill -> 1)\n",
    "    model_df['Species'] = le.fit_transform(model_df.Species)\n",
    "    X = model_df.iloc[:, :-1] # Features, TS(f) only\n",
    "    y = model_df.Species # Labels\n",
    "\n",
    "    if min_range != None:\n",
    "        measured_df = measured_df[measured_df.Range > min_range]\n",
    "\n",
    "    if max_range != None:\n",
    "        measured_df = measured_df[measured_df.Range < max_range]\n",
    "\n",
    "    measured_X = measured_df.iloc[:, 3:-1] # Features, TS(f) only\n",
    "\n",
    "    # -- NESTED CROSS-VALIDATION ----------------------------------------------\n",
    "\n",
    "    model = HyperoptEstimator(classifier = clf,\n",
    "                              preprocessing = preprocessing,\n",
    "                              ex_preprocs = ex_preprocessing,\n",
    "                              algo = tpe.suggest,\n",
    "                              trial_timeout = timeout,\n",
    "                              loss = f1_loss,\n",
    "                              max_evals = max_evals,\n",
    "                              n_jobs = n_jobs)\n",
    "\n",
    "    nested_cv(X, y, model, n_splits, n_folds, unique_id)\n",
    "\n",
    "    # -- RETRAIN MODEL --------------------------------------------------------\n",
    "\n",
    "    print('Retraining model on full dataset')\n",
    "\n",
    "    model = HyperoptEstimator(classifier = clf,\n",
    "                              preprocessing = preprocessing,\n",
    "                              ex_preprocs = ex_preprocessing,\n",
    "                              algo = tpe.suggest,\n",
    "                              trial_timeout = timeout,\n",
    "                              loss = f1_loss,\n",
    "                              max_evals = max_evals,\n",
    "                              n_jobs = n_jobs)\n",
    "\n",
    "    model.fit(X, y, n_folds=n_folds, cv_shuffle=True)\n",
    "\n",
    "    # -- PREDICT CLASSES FOR NEW DATA -----------------------------------------\n",
    "\n",
    "    print('Classifying new data')\n",
    "\n",
    "    y_pred = model.predict(measured_X) # Predict classes for measured TS(f)\n",
    "    y_pred = le.inverse_transform(y_pred) # Transform labels back to species\n",
    "\n",
    "    # -- OUTPUT RESULTS -------------------------------------------------------\n",
    "\n",
    "    measured_df['Prediction'] = y_pred\n",
    "    measured_df.to_pickle(unique_id + '_Predictions.pkl')\n",
    "\n",
    "    with open(unique_id + '_BestParams.pkl', 'wb') as handle:\n",
    "        pickle.dump(model.best_model(), handle)\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824770b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A transposed TS(f) file was created at: \n",
      "C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/AZKABAN-light/ZoopMix_paper/SED_ZoopMix_FTwindow33pl_transposed.csv\n"
     ]
    }
   ],
   "source": [
    "measured_df = tsf_import(ts_SED_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83a12e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ping_index</th>\n",
       "      <th>Range</th>\n",
       "      <th>Depth</th>\n",
       "      <th>185.000</th>\n",
       "      <th>185.500</th>\n",
       "      <th>186.000</th>\n",
       "      <th>186.500</th>\n",
       "      <th>187.000</th>\n",
       "      <th>187.500</th>\n",
       "      <th>188.000</th>\n",
       "      <th>...</th>\n",
       "      <th>251.000</th>\n",
       "      <th>251.500</th>\n",
       "      <th>252.000</th>\n",
       "      <th>252.500</th>\n",
       "      <th>253.000</th>\n",
       "      <th>253.500</th>\n",
       "      <th>254.000</th>\n",
       "      <th>254.500</th>\n",
       "      <th>255.000</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.715900</td>\n",
       "      <td>1.715748</td>\n",
       "      <td>-69.453964</td>\n",
       "      <td>-68.521743</td>\n",
       "      <td>-67.986585</td>\n",
       "      <td>-67.733404</td>\n",
       "      <td>-67.754191</td>\n",
       "      <td>-68.130185</td>\n",
       "      <td>-68.597221</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.595734</td>\n",
       "      <td>-71.547922</td>\n",
       "      <td>-71.147465</td>\n",
       "      <td>-70.542152</td>\n",
       "      <td>-69.911074</td>\n",
       "      <td>-69.383364</td>\n",
       "      <td>-69.019195</td>\n",
       "      <td>-68.878777</td>\n",
       "      <td>-68.918106</td>\n",
       "      <td>2022-01-17 09:45:17.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.191251</td>\n",
       "      <td>2.191001</td>\n",
       "      <td>-77.883264</td>\n",
       "      <td>-78.892482</td>\n",
       "      <td>-78.395912</td>\n",
       "      <td>-77.422381</td>\n",
       "      <td>-76.849307</td>\n",
       "      <td>-77.131158</td>\n",
       "      <td>-78.237995</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.170344</td>\n",
       "      <td>-95.451009</td>\n",
       "      <td>-93.544346</td>\n",
       "      <td>-89.910568</td>\n",
       "      <td>-87.520267</td>\n",
       "      <td>-86.109659</td>\n",
       "      <td>-85.248782</td>\n",
       "      <td>-84.550531</td>\n",
       "      <td>-83.491767</td>\n",
       "      <td>2022-01-17 09:45:17.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.715900</td>\n",
       "      <td>1.715689</td>\n",
       "      <td>-70.599819</td>\n",
       "      <td>-71.358021</td>\n",
       "      <td>-71.912162</td>\n",
       "      <td>-72.177343</td>\n",
       "      <td>-72.210387</td>\n",
       "      <td>-72.189034</td>\n",
       "      <td>-71.994081</td>\n",
       "      <td>...</td>\n",
       "      <td>-69.456054</td>\n",
       "      <td>-69.767954</td>\n",
       "      <td>-70.247306</td>\n",
       "      <td>-70.808972</td>\n",
       "      <td>-71.315128</td>\n",
       "      <td>-71.605663</td>\n",
       "      <td>-71.531900</td>\n",
       "      <td>-71.057052</td>\n",
       "      <td>-70.153700</td>\n",
       "      <td>2022-01-17 09:45:18.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.710103</td>\n",
       "      <td>1.709843</td>\n",
       "      <td>-71.856611</td>\n",
       "      <td>-71.593160</td>\n",
       "      <td>-71.263903</td>\n",
       "      <td>-70.905700</td>\n",
       "      <td>-70.630484</td>\n",
       "      <td>-70.556040</td>\n",
       "      <td>-70.416283</td>\n",
       "      <td>...</td>\n",
       "      <td>-70.926331</td>\n",
       "      <td>-70.803783</td>\n",
       "      <td>-70.527596</td>\n",
       "      <td>-70.179028</td>\n",
       "      <td>-69.844091</td>\n",
       "      <td>-69.592659</td>\n",
       "      <td>-69.455403</td>\n",
       "      <td>-69.465011</td>\n",
       "      <td>-69.534129</td>\n",
       "      <td>2022-01-17 09:45:18.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1.692712</td>\n",
       "      <td>1.692449</td>\n",
       "      <td>-70.293702</td>\n",
       "      <td>-69.615039</td>\n",
       "      <td>-69.264823</td>\n",
       "      <td>-69.141130</td>\n",
       "      <td>-69.228822</td>\n",
       "      <td>-69.573658</td>\n",
       "      <td>-69.870514</td>\n",
       "      <td>...</td>\n",
       "      <td>-70.792217</td>\n",
       "      <td>-70.863150</td>\n",
       "      <td>-70.716718</td>\n",
       "      <td>-70.376147</td>\n",
       "      <td>-69.915707</td>\n",
       "      <td>-69.430619</td>\n",
       "      <td>-68.994180</td>\n",
       "      <td>-68.689533</td>\n",
       "      <td>-68.493175</td>\n",
       "      <td>2022-01-17 09:45:19.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37972</th>\n",
       "      <td>28033</td>\n",
       "      <td>1.762276</td>\n",
       "      <td>1.759939</td>\n",
       "      <td>-113.132523</td>\n",
       "      <td>-112.803816</td>\n",
       "      <td>-114.224551</td>\n",
       "      <td>-114.594160</td>\n",
       "      <td>-112.252564</td>\n",
       "      <td>-110.110741</td>\n",
       "      <td>-109.217116</td>\n",
       "      <td>...</td>\n",
       "      <td>-123.207650</td>\n",
       "      <td>-120.559402</td>\n",
       "      <td>-114.553570</td>\n",
       "      <td>-112.631176</td>\n",
       "      <td>-113.483047</td>\n",
       "      <td>-118.347945</td>\n",
       "      <td>-129.190662</td>\n",
       "      <td>-113.787562</td>\n",
       "      <td>-108.544500</td>\n",
       "      <td>2022-01-17 12:54:21.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37973</th>\n",
       "      <td>28034</td>\n",
       "      <td>1.078235</td>\n",
       "      <td>1.077697</td>\n",
       "      <td>-118.312640</td>\n",
       "      <td>-123.990796</td>\n",
       "      <td>-123.327124</td>\n",
       "      <td>-119.759730</td>\n",
       "      <td>-118.139591</td>\n",
       "      <td>-118.087910</td>\n",
       "      <td>-118.933456</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.110881</td>\n",
       "      <td>-114.346130</td>\n",
       "      <td>-115.713000</td>\n",
       "      <td>-118.186010</td>\n",
       "      <td>-120.146196</td>\n",
       "      <td>-118.397924</td>\n",
       "      <td>-115.607104</td>\n",
       "      <td>-113.822064</td>\n",
       "      <td>-113.064563</td>\n",
       "      <td>2022-01-17 12:54:21.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37974</th>\n",
       "      <td>28076</td>\n",
       "      <td>1.078235</td>\n",
       "      <td>1.077310</td>\n",
       "      <td>-110.922932</td>\n",
       "      <td>-109.982501</td>\n",
       "      <td>-110.333450</td>\n",
       "      <td>-111.489347</td>\n",
       "      <td>-113.320570</td>\n",
       "      <td>-115.734220</td>\n",
       "      <td>-118.376056</td>\n",
       "      <td>...</td>\n",
       "      <td>-117.182811</td>\n",
       "      <td>-115.589224</td>\n",
       "      <td>-113.592313</td>\n",
       "      <td>-112.956288</td>\n",
       "      <td>-114.368750</td>\n",
       "      <td>-118.768406</td>\n",
       "      <td>-118.086530</td>\n",
       "      <td>-110.936258</td>\n",
       "      <td>-106.597035</td>\n",
       "      <td>2022-01-17 12:54:38.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37975</th>\n",
       "      <td>28077</td>\n",
       "      <td>1.049250</td>\n",
       "      <td>1.048023</td>\n",
       "      <td>-113.313526</td>\n",
       "      <td>-110.980939</td>\n",
       "      <td>-110.684654</td>\n",
       "      <td>-111.727588</td>\n",
       "      <td>-114.326816</td>\n",
       "      <td>-119.098485</td>\n",
       "      <td>-120.863880</td>\n",
       "      <td>...</td>\n",
       "      <td>-119.942313</td>\n",
       "      <td>-112.628975</td>\n",
       "      <td>-108.383693</td>\n",
       "      <td>-106.570394</td>\n",
       "      <td>-106.370381</td>\n",
       "      <td>-107.497191</td>\n",
       "      <td>-109.581642</td>\n",
       "      <td>-110.497115</td>\n",
       "      <td>-108.405185</td>\n",
       "      <td>2022-01-17 12:54:38.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37976</th>\n",
       "      <td>28114</td>\n",
       "      <td>1.547788</td>\n",
       "      <td>1.547429</td>\n",
       "      <td>-117.946146</td>\n",
       "      <td>-113.176508</td>\n",
       "      <td>-111.765533</td>\n",
       "      <td>-111.919313</td>\n",
       "      <td>-112.978808</td>\n",
       "      <td>-114.227485</td>\n",
       "      <td>-114.653969</td>\n",
       "      <td>...</td>\n",
       "      <td>-127.874079</td>\n",
       "      <td>-127.082636</td>\n",
       "      <td>-125.690514</td>\n",
       "      <td>-124.551354</td>\n",
       "      <td>-124.196345</td>\n",
       "      <td>-125.111405</td>\n",
       "      <td>-128.368638</td>\n",
       "      <td>-138.266852</td>\n",
       "      <td>-128.257798</td>\n",
       "      <td>2022-01-17 12:54:53.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37977 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ping_index     Range     Depth     185.000     185.500  \\\n",
       "Target_index                                                           \n",
       "0                      0  1.715900  1.715748  -69.453964  -68.521743   \n",
       "1                      0  2.191251  2.191001  -77.883264  -78.892482   \n",
       "2                      1  1.715900  1.715689  -70.599819  -71.358021   \n",
       "3                      2  1.710103  1.709843  -71.856611  -71.593160   \n",
       "4                      3  1.692712  1.692449  -70.293702  -69.615039   \n",
       "...                  ...       ...       ...         ...         ...   \n",
       "37972              28033  1.762276  1.759939 -113.132523 -112.803816   \n",
       "37973              28034  1.078235  1.077697 -118.312640 -123.990796   \n",
       "37974              28076  1.078235  1.077310 -110.922932 -109.982501   \n",
       "37975              28077  1.049250  1.048023 -113.313526 -110.980939   \n",
       "37976              28114  1.547788  1.547429 -117.946146 -113.176508   \n",
       "\n",
       "                 186.000     186.500     187.000     187.500     188.000  ...  \\\n",
       "Target_index                                                              ...   \n",
       "0             -67.986585  -67.733404  -67.754191  -68.130185  -68.597221  ...   \n",
       "1             -78.395912  -77.422381  -76.849307  -77.131158  -78.237995  ...   \n",
       "2             -71.912162  -72.177343  -72.210387  -72.189034  -71.994081  ...   \n",
       "3             -71.263903  -70.905700  -70.630484  -70.556040  -70.416283  ...   \n",
       "4             -69.264823  -69.141130  -69.228822  -69.573658  -69.870514  ...   \n",
       "...                  ...         ...         ...         ...         ...  ...   \n",
       "37972        -114.224551 -114.594160 -112.252564 -110.110741 -109.217116  ...   \n",
       "37973        -123.327124 -119.759730 -118.139591 -118.087910 -118.933456  ...   \n",
       "37974        -110.333450 -111.489347 -113.320570 -115.734220 -118.376056  ...   \n",
       "37975        -110.684654 -111.727588 -114.326816 -119.098485 -120.863880  ...   \n",
       "37976        -111.765533 -111.919313 -112.978808 -114.227485 -114.653969  ...   \n",
       "\n",
       "                 251.000     251.500     252.000     252.500     253.000  \\\n",
       "Target_index                                                               \n",
       "0             -71.595734  -71.547922  -71.147465  -70.542152  -69.911074   \n",
       "1             -92.170344  -95.451009  -93.544346  -89.910568  -87.520267   \n",
       "2             -69.456054  -69.767954  -70.247306  -70.808972  -71.315128   \n",
       "3             -70.926331  -70.803783  -70.527596  -70.179028  -69.844091   \n",
       "4             -70.792217  -70.863150  -70.716718  -70.376147  -69.915707   \n",
       "...                  ...         ...         ...         ...         ...   \n",
       "37972        -123.207650 -120.559402 -114.553570 -112.631176 -113.483047   \n",
       "37973        -114.110881 -114.346130 -115.713000 -118.186010 -120.146196   \n",
       "37974        -117.182811 -115.589224 -113.592313 -112.956288 -114.368750   \n",
       "37975        -119.942313 -112.628975 -108.383693 -106.570394 -106.370381   \n",
       "37976        -127.874079 -127.082636 -125.690514 -124.551354 -124.196345   \n",
       "\n",
       "                 253.500     254.000     254.500     255.000  \\\n",
       "Target_index                                                   \n",
       "0             -69.383364  -69.019195  -68.878777  -68.918106   \n",
       "1             -86.109659  -85.248782  -84.550531  -83.491767   \n",
       "2             -71.605663  -71.531900  -71.057052  -70.153700   \n",
       "3             -69.592659  -69.455403  -69.465011  -69.534129   \n",
       "4             -69.430619  -68.994180  -68.689533  -68.493175   \n",
       "...                  ...         ...         ...         ...   \n",
       "37972        -118.347945 -129.190662 -113.787562 -108.544500   \n",
       "37973        -118.397924 -115.607104 -113.822064 -113.064563   \n",
       "37974        -118.768406 -118.086530 -110.936258 -106.597035   \n",
       "37975        -107.497191 -109.581642 -110.497115 -108.405185   \n",
       "37976        -125.111405 -128.368638 -138.266852 -128.257798   \n",
       "\n",
       "                            Datetime  \n",
       "Target_index                          \n",
       "0            2022-01-17 09:45:17.944  \n",
       "1            2022-01-17 09:45:17.944  \n",
       "2            2022-01-17 09:45:18.478  \n",
       "3            2022-01-17 09:45:18.881  \n",
       "4            2022-01-17 09:45:19.286  \n",
       "...                              ...  \n",
       "37972        2022-01-17 12:54:21.103  \n",
       "37973        2022-01-17 12:54:21.505  \n",
       "37974        2022-01-17 12:54:38.405  \n",
       "37975        2022-01-17 12:54:38.797  \n",
       "37976        2022-01-17 12:54:53.671  \n",
       "\n",
       "[37977 rows x 145 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a649e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
