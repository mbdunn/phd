{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will extract the density of the taxa that might be in the active layer for a range of combinations of modeled backscatter responses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import optimize\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import array as arr\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pylab\n",
    "import glob\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "#from uncertainties import unumpy\n",
    "\n",
    "\n",
    "import sb_tools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median of scattering model resulsts\n",
    "import inverse_method_funs_med as inv\n",
    "\n",
    "# mean of scattering model results\n",
    "#import inverse_method_funs as inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.color_palette(\"viridis\", as_cmap=True)\n",
    "title_font = {\n",
    "    'fontname': 'DejaVu Sans', 'size': '15', 'color': 'black',\n",
    "    'weight': 'medium'\n",
    "}\n",
    "axis_font = {'fontname': 'DejaVu Sans', 'size': '15', 'color': 'black'}\n",
    "\n",
    "savefigs_path= 'C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/Tromsøflaket/CJFAS_manuscript/Figs/'\n",
    "savefigjpg_path= 'C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/Tromsøflaket/CJFAS_manuscript/Figs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read scattering models\n",
    "Import species backscattering cross section matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmabs from ZooScatR model runs + viscous elactic model for mean of fish larvae model by ve=True)\n",
    "fname_sim = '../ZooScatStuff/my_simplified_data_11072022.feather'\n",
    "\n",
    "#90 percent confidence intervals\n",
    "specs, freqs_sim, sigbs_mean, ci_boot = inv.read_scatteringmodelsimulations(fname_sim, nsim=1000, ve=True, percentiles=(2.5,97.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9, 5),facecolor='w', edgecolor='k')\n",
    "plt.plot(freqs_sim,sigbs_mean, linewidth=4)\n",
    "plt.legend(specs, fontsize=16)\n",
    "plt.ylabel('Cross-Sectional Backscatter ($m^{2}$)', axis_font)\n",
    "plt.xlabel('Frequency (kHz)', axis_font)\n",
    "plt.title('Scattering model results', title_font);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample to line up output and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_EV = glob.glob('F:/GLIDER2018/Echosounder/Flaket_SSL/ssl_GLIDER2018*Widebandfrequencyexport*.csv')\n",
    "\n",
    "sv_all = np.zeros((1001,0))\n",
    "times = np.zeros((0))\n",
    "\n",
    "freqs_EV, sv_out_no, times_out_no = inv.read_widebandfrequencyresponse(fname_EV[0])\n",
    "sv_all = np.zeros((len(freqs_EV),0))\n",
    "times = np.zeros((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(6, 8),facecolor='w', edgecolor='k')\n",
    "order=[3,4,2,1,0]\n",
    "for ind in [3,4,2,1,0]:\n",
    "    # Calculate log ci S(TS) = 10*0.434(S(sigbs)/sigbs)\n",
    "    logci_0 = 10*np.log10(sigbs_mean[:,ind]) - (10*(0.434*(sigbs_mean[:,ind]-ci_boot[0,:,ind])/sigbs_mean[:,ind]))\n",
    "    logci_1 = 10*np.log10(sigbs_mean[:,ind]) + 10*(0.434*(ci_boot[1,:,ind]-sigbs_mean[:,ind])/sigbs_mean[:,ind])\n",
    "    \n",
    "    plt.plot(freqs_EV[:],10*np.log10(sigbs_mean[:,ind]), linewidth=1, label=specs[ind])\n",
    "    plt.fill_between(freqs_EV[:],logci_0,logci_1, alpha=0.5)\n",
    "    \n",
    "plt.legend(fontsize=16, loc='right')\n",
    "plt.ylabel('Target Strength (dB re $1m^{2}$)', axis_font)\n",
    "plt.xlabel('Frequency (kHz)', axis_font)\n",
    "plt.title('Scattering model results', title_font);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load density estimate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('SSL_density_median.feather')\n",
    "data_inv = data[data.source=='Inverse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_density = data_inv.groupby(['species','datetime']).mean()['density']\n",
    "inverse = inverse_density.reset_index(1)\n",
    "inv_spec = inverse.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_values = np.reshape(inverse_density.values,(5,70))\n",
    "density_mean = np.mean(density_values, axis=1)\n",
    "density_std = np.std(density_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse method -  Sensitivity analysis\n",
    "Calculate mean predicted density for each active layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make matrix with ci_min, mean and ci_max for all species\n",
    "sensitvity_matrix = [ci_boot0, sigbs_mean, ci_boot1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_EV = glob.glob('F:/GLIDER2018/Echosounder/Flaket_SSL/ssl_GLIDER2018*Widebandfrequencyexport*.csv')\n",
    "nfiles = len(fname_EV)\n",
    "\n",
    "sv_all_q = np.zeros((3,len(freqs_EV), nfiles))\n",
    "\n",
    "\n",
    "for ind in np.arange(nfiles):\n",
    "    freqs_EV, sv_out, times_out = inv.read_widebandfrequencyresponse(fname_EV[ind])\n",
    "\n",
    "    sv_all_q[:,:,ind] = np.percentile(sv_out, (5,50,95), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivitiy analysis iterations\n",
    "\n",
    "n_iterations = 500\n",
    "\n",
    "sensitvity_sig = np.zeros((np.shape(sigbs_mean)))\n",
    "sv_all = np.zeros((len(freqs_EV),0))\n",
    "times = np.zeros((0))\n",
    "density = np.zeros((n_iterations, 5, nfiles))\n",
    "\n",
    "for iterate in np.arange(n_iterations):\n",
    "    # For each species select random q25, q50 or q75\n",
    "    for ind in range(len(specs)):\n",
    "        rand_ind = np.random.randint(0,2)\n",
    "        sensitvity_sig[:,ind] = sensitvity_matrix[rand_ind][:,ind]\n",
    "    # For each file select random q25, q50, q75.\n",
    "    rand_svq = np.random.randint(0,2)\n",
    "    sensitivity_sv = sv_all_q[rand_svq,:,:]\n",
    "        \n",
    "        \n",
    "    for ind in np.arange(nfiles):\n",
    "        times = np.append(times, times_out[0])\n",
    "        \n",
    "        d = optimize.lsq_linear(sensitvity_sig, sensitivity_sv[:,ind], bounds=(0,np.inf))\n",
    "        density[iterate,:,ind] = d.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_5 = np.percentile(density,5,axis=0)\n",
    "q_95 = np.percentile(density,95,axis=0)\n",
    "q_50 = np.percentile(density,50,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
    "axes = axes.flatten()\n",
    "title_letter= ['a) ','b) ','c) ','d) ','e) ','f) ']\n",
    "\n",
    "for ind in range(0,len(specs)):\n",
    "    #plt.plot(density[:,ind,:].T)\n",
    "    ind_inv = np.where(inv_spec==specs[ind])[0][0]\n",
    "    axes[ind].plot(np.arange(0,len(fname_EV)), q_50[ind,:])\n",
    "    axes[ind].plot(np.arange(0,len(fname_EV)), q_50[ind,:]+density_std[ind_inv], '-', c='red',alpha=0.2)\n",
    "    axes[ind].plot(np.arange(0,len(fname_EV)), q_50[ind,:]-density_std[ind_inv], '-',c='red',alpha=0.2)\n",
    "    axes[ind].fill_between(np.arange(0,len(fname_EV)),q_5[ind,:],q_95[ind,:], alpha=0.5)\n",
    "    axes[ind].set_title(title_letter[ind]+specs[ind], title_font)\n",
    "    axes[ind].tick_params(labelsize=14)\n",
    "\n",
    "axes[0].set_ylabel('Predicted Density (ind m$^{-3}$)', axis_font);\n",
    "axes[3].set_ylabel('Predicted Density (ind m$^{-3}$)', axis_font);\n",
    "\n",
    "axes[2].set_xlabel('SSL n$^\\circ$', axis_font);\n",
    "axes[3].set_xlabel('SSL n$^\\circ$', axis_font);\n",
    "axes[4].set_xlabel('SSL n$^\\circ$', axis_font);\n",
    "\n",
    "axes[5].remove()\n",
    "\n",
    "\n",
    "axes[0].set_rasterized(True)\n",
    "axes[1].set_rasterized(True)\n",
    "axes[2].set_rasterized(True)\n",
    "axes[3].set_rasterized(True)\n",
    "axes[4].set_rasterized(True)\n",
    "axes[5].set_rasterized(True)\n",
    "plt.savefig(savefigs_path+'Figure7.pdf', format='pdf', dpi = 300, facecolor='w', bbox_inches='tight')\n",
    "plt.savefig(savefigjpg_path+'Figure7.jpg', format='jpg', dpi = 300, facecolor='w', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_25 = np.percentile(density,25,axis=0)\n",
    "q_75 = np.percentile(density,75,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(q_75-q_25, axis=1)/np.mean(q_50,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(q_75-q_25, axis=1)/np.mean(density_std,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB_env_df = pd.read_excel('C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/Tromsøflaket/SB_env_tromsøflaket2018.xlsx',header=0, engine=\"openpyxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB_env_times = SB_env_df.set_index(['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for ind in range(len(times)):\n",
    "    ind_index = SB_env_times.index.get_loc(times[ind], method=\"nearest\")\n",
    "    index = np.append(index, ind_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataframe with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for specs_ind in range(len(specs)):\n",
    "    for ind in range(nfiles):\n",
    "            SB_env_ind = SB_env_times.index.get_loc(times[ind], method=\"nearest\")\n",
    "            data = data.append({'lat': SB_env_df['latitude (deg)'][SB_env_ind],\n",
    "                                'lon': SB_env_df['longitude (deg)'][SB_env_ind],\n",
    "                                'datetime': times[ind],\n",
    "                                'density': q_50[specs_ind,ind],\n",
    "                                'species': specs[specs_ind],                        \n",
    "                                'source': 'Acoustics'}, \n",
    "                                'ignore_index=True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add net data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_stations_df = pd.read_excel('C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/Tromsøflaket/SeaPatchesStations.xlsx',header=0)\n",
    "tucker_density = pd.read_excel('C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/Tromsøflaket/Tucker Trawl.xlsx', header=79)\n",
    "multinet_density = pd.read_excel('C:/Users/mbd/OneDrive - Akvaplan-niva AS/PhD-APN/ChaptersandExperiments/Tromsøflaket/SP_Multinet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Station 7 from Tucker Trawl\n",
    "stn = 7\n",
    "for stn_ind in range(7,18):\n",
    "    for ind_spec in [0,1,2,3,5]:\n",
    "        data = data.append({'lat' : SP_stations_df['latitude (deg)'][stn_ind-1],\n",
    "                            'lon' : SP_stations_df['longitude (deg)'][stn_ind-1],\n",
    "                            'datetime' : SP_stations_df['Datetime'][stn_ind-1],\n",
    "                            'density': tucker_density['Station ' + str(stn_ind)][ind_spec],\n",
    "                            'species': tucker_density['Species'][ind_spec],\n",
    "                            'source': 'TuckerTrawl'}, \n",
    "                            'ignore_index=True')\n",
    "        data = data.append({'lat' : SP_stations_df['latitude (deg)'][stn_ind-1],\n",
    "                            'lon' : SP_stations_df['longitude (deg)'][stn_ind-1],\n",
    "                            'datetime' : SP_stations_df['Datetime'][stn_ind-1],\n",
    "                            'density': multinet_density['Stn ' + str(stn_ind)][ind_spec],\n",
    "                            'species': multinet_density['Species'][ind_spec],\n",
    "                            'source': 'Multinet'}, \n",
    "                            'ignore_index=True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add log of data as column\n",
    "data['log_density']=np.log10(data.density+1)\n",
    "data['log_density'][np.isnan(data['log_density'])]==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "for ind_spec in range(len(specs)):\n",
    "    ax = plt.subplot(2,3,ind_spec+1)\n",
    "    ax.semilogy(data.source[data.species==specs[ind_spec]],data.density[data.species==specs[ind_spec]], 'kx')\n",
    "    ax.semilogy(data[data.species==specs[ind_spec]].groupby('source').median().index,data[data.species==specs[ind_spec]].groupby('source').median()['density'], 'r.', markersize=12)\n",
    "    ax.set_title(specs[ind_spec], title_font)\n",
    "    if ind_spec==0:\n",
    "        ax.set_ylabel('Density ($ind/m^3$)', axis_font);\n",
    "    if ind_spec==3:\n",
    "        ax.set_ylabel('Density ($ind/m^3$)', axis_font);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted median of sensitity test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
