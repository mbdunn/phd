{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Sv from ANMPA data\n",
    "This notebook will be used to calculate the mean backscatter value for the 2013 and 2014 data from the surveys in the ANMPA area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation zone\n",
    "The area that will be assesed for mean backscatter is determine by the stations used in all the survey years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 69.39130000000\n",
    "max_lat = 70.44650000000\n",
    "\n",
    "min_long = -125.85600000000\n",
    "max_long = -123.19400000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation dates\n",
    "The boats were at the stations location only over certain days. To cut down on processing time we will only look at the time the boats were at the stations\n",
    "\n",
    "2013: 08.02 to 08.08\n",
    "\n",
    "2014: 08.17, 08.22, 08.23, 08.25, 08.26\n",
    "\n",
    "2017:08.15, 08.16, 08.18, 08.23 to 08.27\n",
    "\n",
    "2018: 08.08, 08.09, 08.30, 08.31, 09.01, 09.04, 09.08\n",
    "\n",
    "\n",
    "**Q: Should it be ALL the date BETWEEN the start and end of the stations each year or JUST the days it is AT a station? For now I will do just the specific days to reduce processing time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_2013 = pd.DataFrame(columns={'Sv','Lats','Longs','Depth'})\n",
    "values_2014 = pd.DataFrame(columns={'Sv','Lats','Longs','Depth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Sv, Lats, Longs, Depth]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Sv, Lats, Longs, Depth]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "days_2012 = {'6 au 21 aout','22 aout au 3 sept'}\n",
    "fname = '../data/AmundsenGulf/2012/%s (biomasse).csv' %date\n",
    "values_2012 = pd.read_csv(fname, header=0, usecols=[6,10,32,33])\n",
    "data12 = values_2012.values  \n",
    "\n",
    "\n",
    "#a)2013\n",
    "days_2013 = {'02','03','04','05','06','07','08'}\n",
    "for date in days_2013:\n",
    "    fname = '../data/AmundsenGulf/Biomass_2013/%s-08-13 (biomasse).csv' %date\n",
    "    # Columns are SV-mean, depth, Lat, long.\n",
    "    values_file = pd.read_csv(fname, header=0, usecols=[6,10,32,33])\n",
    "    values_2013.append(values_file)\n",
    "    \n",
    "# Change to a numpy array\n",
    "print(values_2013)\n",
    "data13 = values_2013.values  \n",
    "\n",
    "\n",
    "\n",
    "#b)2014\n",
    "days_2014 = {'17-08','22-08','23-08','24-08','25-08','26-08','27-08'}\n",
    "for date in days_2014:\n",
    "    fname = '../data/AmundsenGulf/Biomass_2014/%s-14 (biomasse).csv' %date\n",
    "    # Columns are SV-mean, depth, Lat, long.\n",
    "    values_file = pd.read_csv(fname, header=0, usecols=[6,10,32,33])\n",
    "    values_2014.append(values_file)\n",
    "    fname2 = '../data/AmundsenGulf/Biomass_2014/%s-14 (biomasse) 2.csv' %date\n",
    "    # Columns are SV-mean, depth, Lat, long.\n",
    "    values_file = pd.read_csv(fname2, header=0, usecols=[6,10,32,33])\n",
    "    values_2014.append(values_file)\n",
    "    \n",
    "# Change to a numpy array\n",
    "print(values_2014)\n",
    "data14 = values_2014.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select values\n",
    "\n",
    "### A) 0-100 m from the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-ccd844359ded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#a)2013\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata13_under100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata13\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata13\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata13_under100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 0"
     ]
    }
   ],
   "source": [
    "#a)2013\n",
    "data13_under100 = data13[data13[:,1]<100,:]\n",
    "print(np.shape(data13_under100))\n",
    "\n",
    "\n",
    "#b)2014\n",
    "data14_under100 = data14[data14[:,1]<100,:]\n",
    "print(np.shape(data14_under100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Within lat and long station box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)2013\n",
    "index13_within = np.where((data13_under100[:,2]>min_lat)*(data13_under100[:,2]<max_lat)*(data13_under100[:,3]>min_long)*(data13_under100[:,3]<max_long))\n",
    "data13_within=data13_under100[index13_within[0],:]\n",
    "print(np.shape(data13_within))\n",
    "\n",
    "#b)2014\n",
    "index14_within = np.where((data14_under100[:,2]>min_lat)*(data14_under100[:,2]<max_lat)*(data14_under100[:,3]>min_long)*(data14_under100[:,3]<max_long))\n",
    "data14_within=data14_under100[index14_within[0],:]\n",
    "print(np.shape(data14_within))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check values that are left, remove outliers.\n",
    "Scatter plot SV in 2013 and 2014\n",
    "**Q: Why are there -1000dB values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(data13_within[:,0], '.')\n",
    "plt.title('2013 Volume backscatter')\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(data14_within[:,0], '.')\n",
    "plt.title('2014 Volume backscatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the -1000 dB values.\n",
    "data13_trimmed = data13_within[data13_within[:,0]>-900,:]\n",
    "data14_trimmed = data14_within[data14_within[:,0]>-900,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(data13_trimmed[:,0], '.')\n",
    "ax1.set_title('2013 Volume backscatter - Trimmed')\n",
    "ax1.set_ylabel('Sv [dB]')\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "ax2.plot(data14_trimmed[:,0], '.')\n",
    "ax2.set_title('2014 Volume backscatter - Trimmed')\n",
    "ax2.set_ylabel('Sv [dB]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate linear mean of Sv\n",
    "Volume backscattering strength to volume backscattering coefficient\n",
    "\n",
    "$S_{v} = 10 log(s_{v})$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$s_{v} = 10^\\frac{S_{v}}{10}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)2013\n",
    "S_v13 = data13_trimmed[:,0]\n",
    "sv13 = 10**(S_v13/10)\n",
    "mean_sv13 = np.mean(sv13)\n",
    "mean_S_v13 = 10*np.log10(mean_sv13)\n",
    "\n",
    "\n",
    "#b)2014\n",
    "S_v14 = data14_trimmed[:,0]\n",
    "sv14 = 10**(S_v14/10)\n",
    "mean_sv14 = np.mean(sv14)\n",
    "mean_S_v14 = 10*np.log10(mean_sv14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate std in log space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) 2013\n",
    "std_sv13 = np.std(sv13)\n",
    "stdm_Sv13 = np.log10(np.abs(mean_sv13 - std_sv13))\n",
    "stdp_Sv13 = np.log10(np.abs(mean_sv13 + std_sv13))\n",
    "\n",
    "#b) 2014\n",
    "std_sv14 = np.std(sv14)\n",
    "stdm_Sv14 = np.log10(np.abs(mean_sv14 - std_sv14))\n",
    "stdp_Sv14 = np.log10(np.abs(mean_sv14 + std_sv14))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2013 mean SV = %f - %f / + %f \\n2014 mean SV = %f - %f / + %f' %(mean_S_v13, stdm_Sv13, stdp_Sv13, mean_S_v14, stdm_Sv14, stdp_Sv14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map location of datapoints\n",
    "**Q: Better res map data point available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "\n",
    "ax.set_ylim([min_lat-1.05, max_lat+1.5])\n",
    "ax.set_xlim([min_long-1.005, max_long+1.005])\n",
    "plt.plot(data13_trimmed[:,3],data13_trimmed[:,2] ,color='blue', linewidth=0.5, marker='.',\n",
    "         transform=ccrs.Geodetic(),)\n",
    "plt.plot(data14_trimmed[:,3],data14_trimmed[:,2] ,color='red', linewidth=0.5, marker='.',\n",
    "         transform=ccrs.Geodetic(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "m = Basemap(projection='npstere',boundinglat=min_lat,lon_0=5,resolution='l')\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='coral',lake_color='aqua')\n",
    "m.drawparallels(np.arange(-80.,81.,20.))\n",
    "m.drawmeridians(np.arange(-180.,181.,20.))\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "# draw tissot's indicatrix to show distortion.\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.plot(data13_trimmed[:,3],data13_trimmed[:,2] ,color='blue', linewidth=0.5, marker='.')\n",
    "\n",
    "plt.plot(data14_trimmed[:,3],data14_trimmed[:,2] ,color='red', linewidth=0.5, marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
